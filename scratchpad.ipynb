{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86867c40-93d0-4fdf-af93-448eaccb3344",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The work here should condense the process require to take an unstructured, or a file with multiple, inconsistent structures within it, and turn it into a 2d object, or Pandas DataFrame, \n",
    "which in turn is translated to into both a SQL - accessible interface from the terminal via DuckDB as well as visually via Datasette and related meta reports, so a user can quickly and \n",
    "painlessly find the issue in a huge messy stack of logs\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1ffe7b79-ab17-4e39-b543-07e2497aba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c2fd059-e9a2-42db-ba79-f0b06832235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = ''.join([\n",
    "        '2024-04-09 20:30:55 ', \n",
    "        'source > ',\n",
    "        'INFO ',\n",
    "        'debezium-sqlserverconnector-facppm1-change-event-source-coordinator ', \n",
    "        ''.join([\n",
    "            'i.d.c.s.SqlServerStreamingChangeEventSource(lambda$getChangeTablesToQuery$4):',\n",
    "            '410 CDC is enabled for table Capture instance \"dbo_CMC_PMDD_DLNQ_DEF\" ',\n",
    "        ]),\n",
    "        ''.join(['[sourceTableId=facppm1.dbo.CMC_PMDD_DLNQ_DEF, ',\n",
    "                 'changeTableId=facppm1.cdc.dbo_CMC_PMDD_DLNQ_DEF_CT, ',\n",
    "                 'startLsn=000658b3:0058f37f:0004, ',\n",
    "                 'changeTableObjectId=1642202092, ',\n",
    "                 'stopLsn=NULL] ',\n",
    "                ]),\n",
    "        'but the table is not on connector\\'s table include list'\n",
    "        # Add more log lines as needed\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "484f82f5-2277-4ef5-b257-1735d0e643da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract = df['log_line'].str.extract(r'{}'.format(r'\"([^\"]+)\"')) \n",
    "type(extract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e0d0038b-9796-4089-9427-0644219fe230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample series of log lines\n",
    "data = {\n",
    "    'log_line': [\n",
    "        line,\n",
    "        \"2024-03-27 15:43:48 platform > Using default value for environment variable SOCAT_KUBE_CPU_LIMIT: '2.0'\",\n",
    "        \"2024-03-09 11:03:26 destination > 2024-03-09 11:01:29 INFO i.a.c.i.d.s.S3ConsumerFactory(lambda$onStartFunction$1):102 - Preparing storage area in destination completed.\",\n",
    "        \"2024-03-09 11:03:26 source > INFO main i.a.i.s.m.MssqlSource(main):660 starting source: class io.airbyte.integrations.source.mssql.MssqlSource\",\n",
    "        \"2024-03-27 15:43:48 platform > source-declarative-manifest-check-99-0-atllj stdoutLocalPort = 9038\",\n",
    "]\n",
    "        # Add more log lines as needed\n",
    "}\n",
    "\n",
    "# line below clears out current df from memory\n",
    "if not df.empty: del df\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# TODO delete these two lines\n",
    "# print(df)\n",
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "00169a78-0d61-4d47-ae6e-84c316031e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         source\n",
       "1       platform\n",
       "2    destination\n",
       "3         source\n",
       "4       platform\n",
       "Name: extracted, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['extracted'] = df['log_line'].str.extract(r'{}'.format(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} (\\w+) >')) \n",
    "df['extracted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c5e74-10d7-460a-bf4a-c793d687c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the regex pattern for each column\n",
    "patterns = {\n",
    "    'Timestamp': r'(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})',\n",
    "    'LogLevel': r'((?<=\\> )INFO)',\n",
    "    'LogMessage': \n",
    "    'ConnectorType': r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} (\\w+) >',\n",
    "    'SourceComponent': r'((?<=INFO )[\\w-]+)',\n",
    "    'TableName': r'\"([^\"]+)\"',\n",
    "    'SourceTableID': r'sourceTableId=([^,]+)',\n",
    "    'ChangeTableID': r'changeTableId=([^,]+)',\n",
    "    'StartLSN': r'startLsn=([^,]+)',\n",
    "    'ChangeTableObjectID': r'changeTableObjectId=([^,]+)',\n",
    "    'StopLSN': r'stopLsn=([^\\]]+)'\n",
    "}\n",
    "\n",
    "# Apply regex patterns to extract each component\n",
    "count = 0\n",
    "for column, pattern in patterns.items():\n",
    "    # if count <= 8:\n",
    "    print(f\"columns: {df.columns}\")\n",
    "    print(f\"extracted value: {df['log_line'].str.extract(r'{}'.format(pattern))}\")\n",
    "    df[column] = df['log_line'].str.extract(r'{}'.format(pattern))  # r'{}'.format(s)\n",
    "    # display(df)\n",
    "    #     count += 1\n",
    "    # else:\n",
    "    #     break\n",
    "# df.drop(columns=['log_line'], inplace=True)  # Optional: remove the original log_line column if not needed\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "94909c33-d8a8-4f4e-aec8-5a301c1904f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_line               2024-04-09 20:30:55 source > INFO debezium-sql...\n",
       "extracted                                                         source\n",
       "Timestamp                                            2024-04-09 20:30:55\n",
       "LogLevel                                                            INFO\n",
       "ConnectorType                                                     source\n",
       "SourceComponent        debezium-sqlserverconnector-facppm1-change-eve...\n",
       "TableName                                          dbo_CMC_PMDD_DLNQ_DEF\n",
       "SourceTableID                              facppm1.dbo.CMC_PMDD_DLNQ_DEF\n",
       "ChangeTableID                       facppm1.cdc.dbo_CMC_PMDD_DLNQ_DEF_CT\n",
       "StartLSN                                          000658b3:0058f37f:0004\n",
       "ChangeTableObjectID                                           1642202092\n",
       "StopLSN                                                             NULL\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df.columns\n",
    "df.loc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90b341-7c3b-4389-b6f3-38e2ed41be3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import pathlib\n",
    "\n",
    "from typing import (\n",
    "    Dict,\n",
    "    Str,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411efead-7134-475c-97e2-29117216ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Union, Optional, Literal\n",
    "import pandas as pd\n",
    "\n",
    "class ExtDataFrame(pd.DataFrame):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ExtDataFrame,  self).__init__(*args, **kwargs)\n",
    "        self.raw_file = Optional[str\n",
    "\n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return ExtDataFrame\n",
    "\n",
    "    def _find_matching_lines(line, line_number, current_entry, entry_line_numbers):\n",
    "        if pattern.match(line):\n",
    "            if current_entry:\n",
    "                # Save the previous log entry and its line numbers\n",
    "                log_entries.append((''.join(current_entry), entry_line_numbers))\n",
    "                current_entry = []\n",
    "                entry_line_numbers = []\n",
    "            # Start a new log entry\n",
    "            current_entry.append(line)\n",
    "            entry_line_numbers.append(line_number)\n",
    "        else:\n",
    "            # Continue adding lines to the current log entry\n",
    "            current_entry.append(line)\n",
    "            entry_line_numbers.append(line_number)\n",
    "\n",
    "        return entry_line_numbers, current_entry\n",
    "\n",
    "    def _fetch_log_entries(file_path: Path, pattern: str):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Regex pattern to identify the start of a log entry (a line starting with a timestamp)\n",
    "        # pattern = re.compile(r'^(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})', re.MULTILINE)\n",
    "        \n",
    "        log_entries = []\n",
    "        current_entry = []\n",
    "        entry_line_numbers = []\n",
    "    \n",
    "        with open(file_path, 'r') as file:\n",
    "            for line_number, line in enumerate(file, start=1):\n",
    "                entry_line_numbers, current_entry = _find_matching_lines(line, line_number, current_entry, entry_line_numbers)\n",
    "            \n",
    "            # Don't forget to add the last entry after the loop ends\n",
    "            if current_entry:\n",
    "                log_entries.append((''.join(current_entry), entry_line_numbers))\n",
    "    \n",
    "        return log_entries\n",
    "\n",
    "    def read_unstructured_text(text: line_parse_rule: str,\n",
    "    def read_unstructured_file(file_path: Union[str, os.PathLike] = None, column_parse_rule: Optional[Dict[str,str], method ): -> pd.DataFrame\n",
    "        \"\"\"This method can be used on a plain text file, or any raw, complex strings where no obvious or consistent 2d structure is present or \n",
    "        known parsing method is available. Instead, the user passes in a parse rule dictionary uses a dictionary with key values representing columns \n",
    "        and Python regex patterns as corresponding values is passed into the function.\n",
    "\n",
    "        For each key-value pair, a column is defined and data matching the pattern is returned.\n",
    "\n",
    "        Args:\n",
    "            \n",
    "\n",
    "        Returns:\n",
    "\n",
    "        Raises:\n",
    "\n",
    "        Example:\n",
    "            >>> test_content = \"2024-03-27 15:45:17 Some log entry\\\\nMore details follow.\\\\n2024-03-27 15:45:18 Another log entry\"\n",
    "            >>> read_log_with_line_numbers(test_content)\n",
    "            [('Some log entry\\\\nMore details follow.', range(1, 3)), ('Another log entry', range(3, 4))]\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "    def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1d044-0731-4475-a0d8-fb2fbfe49022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "file_path = '/Users/bdavis/bengineerdavis/sawmill/test_files/data_engineering_job_99_attempt_1_txt.txt'\n",
    "parse_rules = \n",
    "# log_entries_with_line_numbers = read_log_with_line_numbers(file_path)\n",
    "log_entries_with_line_numbers =  ExtDataFrame().read_unstructured(file_path, parse_rules: Dict[str,str])\n",
    "\n",
    "for entry, line_numbers in log_entries_with_line_numbers:\n",
    "    print(\"Log Entry Lines:\", line_numbers)\n",
    "    print(\"Log Entry Content:\\n\", entry)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbec214-5245-4623-b711-701f1bf2862c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
